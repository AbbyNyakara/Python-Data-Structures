# O(n)

In this case, the code runs n times. refer to the O(n).py file.
In our example, the code will run 10 times to display numbers in range(10)
The number of operations grows as the number of objects
Its steady and predicts

#

Alright! Let’s consider a real-world scenario. Suppose you’re designing a program to process customer orders. If you use an O(n) algorithm, like just iterating through the orders to calculate totals, it’ll handle a growing number of orders smoothly. But, if Quinn’s O(n²) duplicate-checking method is used, things could get painfully slow as the number of orders skyrockets, like during a big sale.

This is why understanding how algorithms scale is so important. Stick with O(n) when you can! What do you think about the trade-off between simplicity and performance here?

# 0n^2

My O(n) stays nice and predictable, growing steadily as input size increases, while Quinn's O(n²) really takes off—like a rocket, as you said—making it much harder to handle for large inputs. That’s why linear algorithms are often the go-to choice for many scenarios. Anything else you’d like to explore about these complexities?

# O(1) / Constant time 

This one is the most efficient algorithm. Like take the add_numbers example. No matter how big the n value is, the algoorithm will run just once. One operation. 
